{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[poincare]\n",
      "(distance)\n",
      "(distance2plane)\n",
      "(gyrovector_parallel_transport)\n",
      "(mobius_add)\n",
      "(Mobius Matvec)\n",
      "(mobius_sigmoid_apply)\n",
      "parallel_transport\n",
      "\n",
      "[product]\n",
      "(torus_embedding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multiple 'tvtk.toolkits' plugins found for toolkit 'qt': tvtk.pyface.ui.qt4.init, tvtk.pyface.ui.qt4.init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[stereographic]\n",
      "(distance)\n",
      "(distance2plane)\n",
      "(euclidean_grid)\n",
      "(geodesic_grid)\n",
      "(midpoint)\n",
      "(mobius_add)\n",
      "(mobius_matvec)\n",
      "(orthogonal_sigmoid_apply)\n",
      "(orthogonal_projection)\n",
      "(orthogonal_projection_pub)\n",
      "parallel_transport\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from docs.plots import * \n",
    "import numpy as np\n",
    "from globals import COLORS\n",
    "\n",
    "gpu = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_global_seed(seed: int):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  # If using CUDA\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def random_pc_vector(dim):\n",
    "  while True:\n",
    "    x = (2 * torch.rand(dim)) - 1  # random in (-1, 1)\n",
    "    if torch.norm(x) < 1:\n",
    "      return x\n",
    "    \n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eee5725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'torch.cuda',\n",
       " '__doc__': '\\nThis package adds support for CUDA tensor types.\\n\\nIt implements the same function as CPU tensors, but they utilize\\nGPUs for computation.\\n\\nIt is lazily initialized, so you can always import it, and use\\n:func:`is_available()` to determine if your system supports CUDA.\\n\\n:ref:`cuda-semantics` has more details about working with CUDA.\\n',\n",
       " '__package__': 'torch.cuda',\n",
       " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x2591c0bb5b0>,\n",
       " '__spec__': ModuleSpec(name='torch.cuda', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000002591C0BB5B0>, origin='c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py', submodule_search_locations=['c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda']),\n",
       " '__path__': ['c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda'],\n",
       " '__file__': 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py',\n",
       " '__cached__': 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__pycache__\\\\__init__.cpython-310.pyc',\n",
       " '__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __feature_import__>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x00000259756EEA70>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'aiter': <function aiter(async_iterable, /)>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'anext': <function anext>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'Exception': Exception,\n",
       "  'TypeError': TypeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'SystemExit': SystemExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'ImportError': ImportError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'OSError': OSError,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'WindowsError': OSError,\n",
       "  'EOFError': EOFError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'NameError': NameError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'TabError': TabError,\n",
       "  'LookupError': LookupError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ValueError': ValueError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'SystemError': SystemError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'BufferError': BufferError,\n",
       "  'Warning': Warning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'EncodingWarning': EncodingWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': Type license() to see the full license text,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "  '__pybind11_internals_v4_mingw_libstdcpp_cxxabi1014__': <capsule object NULL at 0x0000025941550570>,\n",
       "  '__feature_import__': <function __feature_import__>,\n",
       "  '__orig_import__': <function __lazy_import__>,\n",
       "  'qApp': <PySide6.QtWidgets.QApplication(0x25941499450) at 0x0000025943B60C80>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x0000025975B337C0>>},\n",
       " '__annotations__': {'_queued_calls': typing.List[typing.Tuple[typing.Callable[[], NoneType], typing.List[str]]],\n",
       "  'has_half': bool,\n",
       "  'has_magma': bool,\n",
       "  'default_generators': typing.Tuple[torch._C.Generator],\n",
       "  '_cached_device_count': typing.Optional[int]},\n",
       " 'importlib': <module 'importlib' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\importlib\\\\__init__.py'>,\n",
       " 'os': <module 'os' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\os.py'>,\n",
       " 'threading': <module 'threading' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\threading.py'>,\n",
       " 'traceback': <module 'traceback' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\traceback.py'>,\n",
       " 'warnings': <module 'warnings' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\warnings.py'>,\n",
       " 'lru_cache': <function functools.lru_cache(maxsize=128, typed=False)>,\n",
       " 'Any': typing.Any,\n",
       " 'Callable': typing.Callable,\n",
       " 'cast': <function typing.cast(typ, val)>,\n",
       " 'List': typing.List,\n",
       " 'Optional': typing.Optional,\n",
       " 'Tuple': typing.Tuple,\n",
       " 'Union': typing.Union,\n",
       " 'torch': <module 'torch' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'>,\n",
       " '_device': torch.device,\n",
       " '_dummy_type': <function torch._utils._dummy_type(name: str) -> type>,\n",
       " '_LazySeedTracker': torch._utils._LazySeedTracker,\n",
       " 'classproperty': <function torch._utils.classproperty(func)>,\n",
       " 'Device': typing.Union[torch.device, str, int, NoneType],\n",
       " 'gds': <module 'torch.cuda.gds' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\gds.py'>,\n",
       " '_utils': <module 'torch.cuda._utils' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\_utils.py'>,\n",
       " '_get_device_index': <function torch.cuda._utils._get_device_index(device: Any, optional: bool = False, allow_cpu: bool = False) -> int>,\n",
       " 'graphs': <module 'torch.cuda.graphs' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\graphs.py'>,\n",
       " 'CUDAGraph': torch.cuda.graphs.CUDAGraph,\n",
       " 'graph': torch.cuda.graphs.graph,\n",
       " 'graph_pool_handle': <function torch.cuda.graphs.graph_pool_handle()>,\n",
       " 'is_current_stream_capturing': <function torch.cuda.graphs.is_current_stream_capturing()>,\n",
       " 'make_graphed_callables': <function torch.cuda.graphs.make_graphed_callables(callables, sample_args, num_warmup_iters=3, allow_unused_input=False, pool=None)>,\n",
       " 'streams': <module 'torch.cuda.streams' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\streams.py'>,\n",
       " 'Event': torch.cuda.streams.Event,\n",
       " 'ExternalStream': torch.cuda.streams.ExternalStream,\n",
       " 'Stream': torch.cuda.streams.Stream,\n",
       " '_cudart': <module 'torch._C._cudart'>,\n",
       " '_initialized': False,\n",
       " '_tls': <_thread._local at 0x2591c118d60>,\n",
       " '_initialization_lock': <unlocked _thread.lock object at 0x000002591C10E780>,\n",
       " '_queued_calls': [(<function torch.cuda._check_capability()>,\n",
       "   ['  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 18, in <module>\\n    app.launch_new_instance()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 1075, in launch_instance\\n    app.start()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 739, in start\\n    self.io_loop.start()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\tornado\\\\platform\\\\asyncio.py\", line 205, in start\\n    self.asyncio_loop.run_forever()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\base_events.py\", line 603, in run_forever\\n    self._run_once()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\base_events.py\", line 1909, in _run_once\\n    handle._run()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 545, in dispatch_queue\\n    await self.process_one()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 534, in process_one\\n    await dispatch(*args)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 437, in dispatch_shell\\n    await result\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 362, in execute_request\\n    await super().execute_request(stream, ident, parent)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 778, in execute_request\\n    reply_content = await reply_content\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 449, in do_execute\\n    res = shell.run_cell(\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 549, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3075, in run_cell\\n    result = self._run_cell(\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3130, in _run_cell\\n    result = runner(coro)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\async_helpers.py\", line 128, in _pseudo_sync_runner\\n    coro.send(None)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3334, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3517, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3577, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n',\n",
       "    '  File \"C:\\\\Users\\\\prfej\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_8252\\\\4169340467.py\", line 2, in <module>\\n    import torch\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\__init__.py\", line 2046, in <module>\\n    _C._initExtension(_manager_path())\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 264, in <module>\\n    _lazy_call(_check_capability)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 261, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']),\n",
       "  (<function torch.cuda._check_cubins()>,\n",
       "   ['  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 18, in <module>\\n    app.launch_new_instance()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 1075, in launch_instance\\n    app.start()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 739, in start\\n    self.io_loop.start()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\tornado\\\\platform\\\\asyncio.py\", line 205, in start\\n    self.asyncio_loop.run_forever()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\base_events.py\", line 603, in run_forever\\n    self._run_once()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\base_events.py\", line 1909, in _run_once\\n    handle._run()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 545, in dispatch_queue\\n    await self.process_one()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 534, in process_one\\n    await dispatch(*args)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 437, in dispatch_shell\\n    await result\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 362, in execute_request\\n    await super().execute_request(stream, ident, parent)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 778, in execute_request\\n    reply_content = await reply_content\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 449, in do_execute\\n    res = shell.run_cell(\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 549, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3075, in run_cell\\n    result = self._run_cell(\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3130, in _run_cell\\n    result = runner(coro)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\async_helpers.py\", line 128, in _pseudo_sync_runner\\n    coro.send(None)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3334, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3517, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3577, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n',\n",
       "    '  File \"C:\\\\Users\\\\prfej\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_8252\\\\4169340467.py\", line 2, in <module>\\n    import torch\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\__init__.py\", line 2046, in <module>\\n    _C._initExtension(_manager_path())\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 265, in <module>\\n    _lazy_call(_check_cubins)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 261, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']),\n",
       "  (<function torch.cuda._register_triton_kernels()>,\n",
       "   ['  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 18, in <module>\\n    app.launch_new_instance()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 1075, in launch_instance\\n    app.start()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 739, in start\\n    self.io_loop.start()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\tornado\\\\platform\\\\asyncio.py\", line 205, in start\\n    self.asyncio_loop.run_forever()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\base_events.py\", line 603, in run_forever\\n    self._run_once()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\base_events.py\", line 1909, in _run_once\\n    handle._run()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\asyncio\\\\events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 545, in dispatch_queue\\n    await self.process_one()\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 534, in process_one\\n    await dispatch(*args)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 437, in dispatch_shell\\n    await result\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 362, in execute_request\\n    await super().execute_request(stream, ident, parent)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 778, in execute_request\\n    reply_content = await reply_content\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 449, in do_execute\\n    res = shell.run_cell(\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 549, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3075, in run_cell\\n    result = self._run_cell(\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3130, in _run_cell\\n    result = runner(coro)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\async_helpers.py\", line 128, in _pseudo_sync_runner\\n    coro.send(None)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3334, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3517, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3577, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n',\n",
       "    '  File \"C:\\\\Users\\\\prfej\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_8252\\\\4169340467.py\", line 2, in <module>\\n    import torch\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\__init__.py\", line 2046, in <module>\\n    _C._initExtension(_manager_path())\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n',\n",
       "    '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n',\n",
       "    '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 1604, in <module>\\n    _lazy_call(_register_triton_kernels)\\n',\n",
       "    '  File \"c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 261, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n'])],\n",
       " '_is_in_bad_fork': <function torch._C._cuda_isInBadFork>,\n",
       " '_device_t': typing.Union[torch.device, str, int, NoneType],\n",
       " '_HAS_PYNVML': False,\n",
       " '_PYNVML_ERR': None,\n",
       " '_lazy_seed_tracker': <torch._utils._LazySeedTracker at 0x2591c105060>,\n",
       " '_CudaDeviceProperties': torch._C._CudaDeviceProperties,\n",
       " '_exchange_device': <function torch._C._cuda_exchangeDevice>,\n",
       " '_maybe_exchange_device': <function torch._C._cuda_maybeExchangeDevice>,\n",
       " 'has_half': True,\n",
       " 'has_magma': True,\n",
       " 'default_generators': (),\n",
       " '_is_compiled': <function torch.cuda._is_compiled() -> bool>,\n",
       " '_nvml_based_avail': <function torch.cuda._nvml_based_avail() -> bool>,\n",
       " 'is_available': <function torch.cuda.is_available() -> bool>,\n",
       " 'is_bf16_supported': <function torch.cuda.is_bf16_supported(including_emulation: bool = True)>,\n",
       " '_check_bf16_tensor_supported': <functools._lru_cache_wrapper at 0x2591c120460>,\n",
       " '_sleep': <function torch.cuda._sleep(cycles)>,\n",
       " '_extract_arch_version': <function torch.cuda._extract_arch_version(arch_string: str)>,\n",
       " '_check_capability': <function torch.cuda._check_capability()>,\n",
       " '_check_cubins': <function torch.cuda._check_cubins()>,\n",
       " 'is_initialized': <function torch.cuda.is_initialized()>,\n",
       " '_lazy_call': <function torch.cuda._lazy_call(callable, **kwargs)>,\n",
       " 'DeferredCudaCallError': torch.cuda.DeferredCudaCallError,\n",
       " 'OutOfMemoryError': torch.OutOfMemoryError,\n",
       " 'init': <function torch.cuda.init()>,\n",
       " '_lazy_init': <function torch.cuda._lazy_init()>,\n",
       " 'cudart': <function torch.cuda.cudart()>,\n",
       " 'cudaStatus': torch.cuda.cudaStatus,\n",
       " 'CudaError': torch.cuda.CudaError,\n",
       " 'check_error': <function torch.cuda.check_error(res: int) -> None>,\n",
       " '_DeviceGuard': torch.cuda._DeviceGuard,\n",
       " 'device': torch.cuda.device,\n",
       " 'device_of': torch.cuda.device_of,\n",
       " 'set_device': <function torch.cuda.set_device(device: Union[torch.device, str, int, NoneType]) -> None>,\n",
       " 'get_device_name': <function torch.cuda.get_device_name(device: Union[torch.device, str, int, NoneType] = None) -> str>,\n",
       " 'get_device_capability': <function torch.cuda.get_device_capability(device: Union[torch.device, str, int, NoneType] = None) -> Tuple[int, int]>,\n",
       " 'get_device_properties': <function torch.cuda.get_device_properties(device: Union[torch.device, str, int, NoneType] = None) -> torch._C._CudaDeviceProperties>,\n",
       " 'can_device_access_peer': <function torch.cuda.can_device_access_peer(device: Union[torch.device, str, int, NoneType], peer_device: Union[torch.device, str, int, NoneType]) -> bool>,\n",
       " 'StreamContext': torch.cuda.StreamContext,\n",
       " 'stream': <function torch.cuda.stream(stream: Optional[ForwardRef('torch.cuda.Stream')]) -> torch.cuda.StreamContext>,\n",
       " '_set_stream_by_id': <function torch.cuda._set_stream_by_id(stream_id, device_index, device_type)>,\n",
       " 'set_stream': <function torch.cuda.set_stream(stream: torch.cuda.streams.Stream)>,\n",
       " '_parse_visible_devices': <function torch.cuda._parse_visible_devices() -> Union[List[int], List[str]]>,\n",
       " '_raw_device_count_amdsmi': <function torch.cuda._raw_device_count_amdsmi() -> int>,\n",
       " '_raw_device_count_nvml': <function torch.cuda._raw_device_count_nvml() -> int>,\n",
       " '_raw_device_uuid_amdsmi': <function torch.cuda._raw_device_uuid_amdsmi() -> Optional[List[str]]>,\n",
       " '_raw_device_uuid_nvml': <function torch.cuda._raw_device_uuid_nvml() -> Optional[List[str]]>,\n",
       " '_transform_uuid_to_ordinals': <function torch.cuda._transform_uuid_to_ordinals(candidates: List[str], uuids: List[str]) -> List[int]>,\n",
       " '_device_count_amdsmi': <function torch.cuda._device_count_amdsmi() -> int>,\n",
       " '_device_count_nvml': <function torch.cuda._device_count_nvml() -> int>,\n",
       " '_get_nvml_device_index': <function torch.cuda._get_nvml_device_index(device: Union[torch.device, str, int, NoneType]) -> int>,\n",
       " '_cached_device_count': None,\n",
       " 'device_count': <function torch.cuda.device_count() -> int>,\n",
       " 'get_arch_list': <function torch.cuda.get_arch_list() -> List[str]>,\n",
       " 'get_gencode_flags': <function torch.cuda.get_gencode_flags() -> str>,\n",
       " 'current_device': <function torch.cuda.current_device() -> int>,\n",
       " 'synchronize': <function torch.cuda.synchronize(device: Union[torch.device, str, int, NoneType] = None) -> None>,\n",
       " 'ipc_collect': <function torch.cuda.ipc_collect()>,\n",
       " 'current_stream': <function torch.cuda.current_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.cuda.streams.Stream>,\n",
       " 'default_stream': <function torch.cuda.default_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.cuda.streams.Stream>,\n",
       " 'current_blas_handle': <function torch.cuda.current_blas_handle()>,\n",
       " 'set_sync_debug_mode': <function torch.cuda.set_sync_debug_mode(debug_mode: Union[int, str]) -> None>,\n",
       " 'get_sync_debug_mode': <function torch.cuda.get_sync_debug_mode() -> int>,\n",
       " '_get_pynvml_handler': <function torch.cuda._get_pynvml_handler(device: Union[torch.device, str, int, NoneType] = None)>,\n",
       " '_get_amdsmi_handler': <function torch.cuda._get_amdsmi_handler(device: Union[torch.device, str, int, NoneType] = None)>,\n",
       " '_get_amdsmi_device_index': <function torch.cuda._get_amdsmi_device_index(device: Union[torch.device, str, int, NoneType]) -> int>,\n",
       " '_get_amdsmi_device_memory_used': <function torch.cuda._get_amdsmi_device_memory_used(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " '_get_amdsmi_memory_usage': <function torch.cuda._get_amdsmi_memory_usage(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " '_get_amdsmi_utilization': <function torch.cuda._get_amdsmi_utilization(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " '_get_amdsmi_temperature': <function torch.cuda._get_amdsmi_temperature(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " '_get_amdsmi_power_draw': <function torch.cuda._get_amdsmi_power_draw(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " '_get_amdsmi_clock_rate': <function torch.cuda._get_amdsmi_clock_rate(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'device_memory_used': <function torch.cuda.device_memory_used(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'memory_usage': <function torch.cuda.memory_usage(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'utilization': <function torch.cuda.utilization(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'temperature': <function torch.cuda.temperature(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'power_draw': <function torch.cuda.power_draw(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'clock_rate': <function torch.cuda.clock_rate(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " '_get_device': <function torch.cuda._get_device(device: Union[int, str, torch.device]) -> torch.device>,\n",
       " '_get_generator': <function torch.cuda._get_generator(device: torch.device) -> torch._C.Generator>,\n",
       " '_set_rng_state_offset': <function torch.cuda._set_rng_state_offset(offset: int, device: Union[int, str, torch.device] = 'cuda') -> None>,\n",
       " '_get_rng_state_offset': <function torch.cuda._get_rng_state_offset(device: Union[int, str, torch.device] = 'cuda') -> int>,\n",
       " '_memory_viz': <module 'torch.cuda._memory_viz' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\_memory_viz.py'>,\n",
       " 'memory': <module 'torch.cuda.memory' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\memory.py'>,\n",
       " 'caching_allocator_alloc': <function torch.cuda.memory.caching_allocator_alloc(size, device: Union[torch.device, str, int, NoneType] = None, stream=None)>,\n",
       " 'caching_allocator_delete': <function torch.cuda.memory.caching_allocator_delete(mem_ptr)>,\n",
       " 'caching_allocator_enable': <function torch.cuda.memory.caching_allocator_enable(value: bool = True) -> None>,\n",
       " 'get_per_process_memory_fraction': <function torch.cuda.memory.get_per_process_memory_fraction(device: Union[torch.device, str, int, NoneType] = None) -> float>,\n",
       " 'set_per_process_memory_fraction': <function torch.cuda.memory.set_per_process_memory_fraction(fraction, device: Union[torch.device, str, int, NoneType] = None) -> None>,\n",
       " 'empty_cache': <function torch.cuda.memory.empty_cache() -> None>,\n",
       " 'memory_stats': <function torch.cuda.memory.memory_stats(device: Union[torch.device, str, int, NoneType] = None) -> Dict[str, Any]>,\n",
       " 'memory_stats_as_nested_dict': <function torch.cuda.memory.memory_stats_as_nested_dict(device: Union[torch.device, str, int, NoneType] = None) -> Dict[str, Any]>,\n",
       " 'reset_accumulated_memory_stats': <function torch.cuda.memory.reset_accumulated_memory_stats(device: Union[torch.device, str, int, NoneType] = None) -> None>,\n",
       " 'reset_peak_memory_stats': <function torch.cuda.memory.reset_peak_memory_stats(device: Union[torch.device, str, int, NoneType] = None) -> None>,\n",
       " 'reset_max_memory_allocated': <function torch.cuda.memory.reset_max_memory_allocated(device: Union[torch.device, str, int, NoneType] = None) -> None>,\n",
       " 'reset_max_memory_cached': <function torch.cuda.memory.reset_max_memory_cached(device: Union[torch.device, str, int, NoneType] = None) -> None>,\n",
       " 'memory_allocated': <function torch.cuda.memory.memory_allocated(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'max_memory_allocated': <function torch.cuda.memory.max_memory_allocated(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'memory_reserved': <function torch.cuda.memory.memory_reserved(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'max_memory_reserved': <function torch.cuda.memory.max_memory_reserved(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'memory_cached': <function torch.cuda.memory.memory_cached(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'max_memory_cached': <function torch.cuda.memory.max_memory_cached(device: Union[torch.device, str, int, NoneType] = None) -> int>,\n",
       " 'memory_snapshot': <function torch.cuda.memory.memory_snapshot()>,\n",
       " 'memory_summary': <function torch.cuda.memory.memory_summary(device: Union[torch.device, str, int, NoneType] = None, abbreviated: bool = False) -> str>,\n",
       " 'list_gpu_processes': <function torch.cuda.memory.list_gpu_processes(device: Union[torch.device, str, int, NoneType] = None) -> str>,\n",
       " 'mem_get_info': <function torch.cuda.memory.mem_get_info(device: Union[torch.device, str, int, NoneType] = None) -> Tuple[int, int]>,\n",
       " 'get_allocator_backend': <function torch.cuda.memory.get_allocator_backend() -> str>,\n",
       " 'CUDAPluggableAllocator': torch.cuda.memory.CUDAPluggableAllocator,\n",
       " 'change_current_allocator': <function torch.cuda.memory.change_current_allocator(allocator: torch.cuda.memory._CUDAAllocator) -> None>,\n",
       " 'MemPool': torch.cuda.memory.MemPool,\n",
       " 'MemPoolContext': torch.cuda.memory.MemPoolContext,\n",
       " 'use_mem_pool': <function torch.cuda.memory.use_mem_pool(pool: torch.cuda.memory.MemPool, device: Union[torch.device, str, int, NoneType] = None)>,\n",
       " 'random': <module 'torch.cuda.random' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\random.py'>,\n",
       " 'get_rng_state': <function torch.cuda.random.get_rng_state(device: Union[int, str, torch.device] = 'cuda') -> torch.Tensor>,\n",
       " 'get_rng_state_all': <function torch.cuda.random.get_rng_state_all() -> List[torch.Tensor]>,\n",
       " 'set_rng_state': <function torch.cuda.random.set_rng_state(new_state: torch.Tensor, device: Union[int, str, torch.device] = 'cuda') -> None>,\n",
       " 'set_rng_state_all': <function torch.cuda.random.set_rng_state_all(new_states: Iterable[torch.Tensor]) -> None>,\n",
       " 'manual_seed': <function torch.cuda.random.manual_seed(seed: int) -> None>,\n",
       " 'manual_seed_all': <function torch.cuda.random.manual_seed_all(seed: int) -> None>,\n",
       " 'seed': <function torch.cuda.random.seed() -> None>,\n",
       " 'seed_all': <function torch.cuda.random.seed_all() -> None>,\n",
       " 'initial_seed': <function torch.cuda.random.initial_seed() -> int>,\n",
       " '_lazy_new': <staticmethod(<function _lazy_new at 0x000002591C26F880>)>,\n",
       " '_CudaBase': torch.cuda._CudaBase,\n",
       " '_warn_typed_storage_removal': <function torch.storage._warn_typed_storage_removal(stacklevel=2)>,\n",
       " 'ByteStorage': torch.cuda.ByteStorage,\n",
       " 'DoubleStorage': torch.cuda.DoubleStorage,\n",
       " 'FloatStorage': torch.cuda.FloatStorage,\n",
       " 'HalfStorage': torch.cuda.HalfStorage,\n",
       " 'LongStorage': torch.cuda.LongStorage,\n",
       " 'IntStorage': torch.cuda.IntStorage,\n",
       " 'ShortStorage': torch.cuda.ShortStorage,\n",
       " 'CharStorage': torch.cuda.CharStorage,\n",
       " 'BoolStorage': torch.cuda.BoolStorage,\n",
       " 'BFloat16Storage': torch.cuda.BFloat16Storage,\n",
       " 'ComplexDoubleStorage': torch.cuda.ComplexDoubleStorage,\n",
       " 'ComplexFloatStorage': torch.cuda.ComplexFloatStorage,\n",
       " '_WrappedTritonKernel': torch.cuda._WrappedTritonKernel,\n",
       " '_register_triton_kernels': <function torch.cuda._register_triton_kernels()>,\n",
       " 'amp': <module 'torch.cuda.amp' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\amp\\\\__init__.py'>,\n",
       " 'jiterator': <module 'torch.cuda.jiterator' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\jiterator.py'>,\n",
       " 'nvtx': <module 'torch.cuda.nvtx' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\nvtx.py'>,\n",
       " 'profiler': <module 'torch.cuda.profiler' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\profiler.py'>,\n",
       " 'sparse': <module 'torch.cuda.sparse' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\sparse.py'>,\n",
       " 'tunable': <module 'torch.cuda.tunable' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\tunable.py'>,\n",
       " '__all__': ['BFloat16Storage',\n",
       "  'BFloat16Tensor',\n",
       "  'BoolStorage',\n",
       "  'BoolTensor',\n",
       "  'ByteStorage',\n",
       "  'ByteTensor',\n",
       "  'CharStorage',\n",
       "  'CharTensor',\n",
       "  'ComplexDoubleStorage',\n",
       "  'ComplexFloatStorage',\n",
       "  'DoubleStorage',\n",
       "  'DoubleTensor',\n",
       "  'FloatStorage',\n",
       "  'FloatTensor',\n",
       "  'HalfStorage',\n",
       "  'HalfTensor',\n",
       "  'IntStorage',\n",
       "  'IntTensor',\n",
       "  'LongStorage',\n",
       "  'LongTensor',\n",
       "  'ShortStorage',\n",
       "  'ShortTensor',\n",
       "  'CUDAGraph',\n",
       "  'CudaError',\n",
       "  'DeferredCudaCallError',\n",
       "  'Event',\n",
       "  'ExternalStream',\n",
       "  'Stream',\n",
       "  'StreamContext',\n",
       "  'amp',\n",
       "  'caching_allocator_alloc',\n",
       "  'caching_allocator_delete',\n",
       "  'caching_allocator_enable',\n",
       "  'can_device_access_peer',\n",
       "  'check_error',\n",
       "  'cudaStatus',\n",
       "  'cudart',\n",
       "  'current_blas_handle',\n",
       "  'current_device',\n",
       "  'current_stream',\n",
       "  'default_generators',\n",
       "  'default_stream',\n",
       "  'device',\n",
       "  'device_count',\n",
       "  'device_memory_used',\n",
       "  'device_of',\n",
       "  'empty_cache',\n",
       "  'get_allocator_backend',\n",
       "  'CUDAPluggableAllocator',\n",
       "  'change_current_allocator',\n",
       "  'get_arch_list',\n",
       "  'get_device_capability',\n",
       "  'get_device_name',\n",
       "  'get_device_properties',\n",
       "  'get_gencode_flags',\n",
       "  'get_per_process_memory_fraction',\n",
       "  'get_rng_state',\n",
       "  'get_rng_state_all',\n",
       "  'get_sync_debug_mode',\n",
       "  'graph',\n",
       "  'graph_pool_handle',\n",
       "  'graphs',\n",
       "  'has_half',\n",
       "  'has_magma',\n",
       "  'init',\n",
       "  'initial_seed',\n",
       "  'ipc_collect',\n",
       "  'is_available',\n",
       "  'is_bf16_supported',\n",
       "  'is_current_stream_capturing',\n",
       "  'is_initialized',\n",
       "  'jiterator',\n",
       "  'list_gpu_processes',\n",
       "  'make_graphed_callables',\n",
       "  'manual_seed',\n",
       "  'manual_seed_all',\n",
       "  'max_memory_allocated',\n",
       "  'max_memory_cached',\n",
       "  'max_memory_reserved',\n",
       "  'mem_get_info',\n",
       "  'memory',\n",
       "  'memory_allocated',\n",
       "  'memory_cached',\n",
       "  'memory_reserved',\n",
       "  'memory_snapshot',\n",
       "  'memory_stats',\n",
       "  'memory_stats_as_nested_dict',\n",
       "  'memory_summary',\n",
       "  'memory_usage',\n",
       "  'MemPool',\n",
       "  'MemPoolContext',\n",
       "  'use_mem_pool',\n",
       "  'temperature',\n",
       "  'power_draw',\n",
       "  'clock_rate',\n",
       "  'nccl',\n",
       "  'nvtx',\n",
       "  'profiler',\n",
       "  'random',\n",
       "  'reset_accumulated_memory_stats',\n",
       "  'reset_max_memory_allocated',\n",
       "  'reset_max_memory_cached',\n",
       "  'reset_peak_memory_stats',\n",
       "  'seed',\n",
       "  'seed_all',\n",
       "  'set_device',\n",
       "  'set_per_process_memory_fraction',\n",
       "  'set_rng_state',\n",
       "  'set_rng_state_all',\n",
       "  'set_stream',\n",
       "  'set_sync_debug_mode',\n",
       "  'sparse',\n",
       "  'stream',\n",
       "  'streams',\n",
       "  'synchronize',\n",
       "  'tunable',\n",
       "  'utilization'],\n",
       " 'ByteTensor': torch.cuda.ByteTensor,\n",
       " 'CharTensor': torch.cuda.CharTensor,\n",
       " 'DoubleTensor': torch.cuda.DoubleTensor,\n",
       " 'FloatTensor': torch.cuda.FloatTensor,\n",
       " 'IntTensor': torch.cuda.IntTensor,\n",
       " 'LongTensor': torch.cuda.LongTensor,\n",
       " 'ShortTensor': torch.cuda.ShortTensor,\n",
       " 'HalfTensor': torch.cuda.HalfTensor,\n",
       " 'BoolTensor': torch.cuda.BoolTensor,\n",
       " 'BFloat16Tensor': torch.cuda.BFloat16Tensor,\n",
       " 'nccl': <module 'torch.cuda.nccl' from 'c:\\\\Users\\\\prfej\\\\miniconda3\\\\envs\\\\gnn.test\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\nccl.py'>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abffc64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\prfej\\OneDrive\\Education\\BHT - Apllied Mathematics\\THESIS\\Adaptive-Point-HGNN\\geoopt-universal-manifold\\geoopt\\optim\\radam.py:85: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1661.)\n",
      "  grad.add_(weight_decay, point)\n",
      "100%|| 10/10 [00:18<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "x   = random_pc_vector(2)\n",
    "y   = random_pc_vector(2)\n",
    "v1  = torch.rand(2)/5\n",
    "v2  = torch.rand(2)/5\n",
    "M   = torch.tensor([[-1, -1.5], [0.2, 0.5]])\n",
    "\n",
    "# POINCARE\n",
    "\n",
    "#poincare.distance.show(x,device)\n",
    "#poincare.distance2plane.show(x,v1,device)\n",
    "#poincare.gyrovector_parallel_transport.show(x,y,device)\n",
    "#poincare.mobius_add.show(x,y,device)\n",
    "#poincare.mobius_matvec.show(M,x,device)\n",
    "#poincare.mobius_sigmoid_apply.show(x,device)\n",
    "#poincare.parallel_transport.show(x,y,v1,v2,device)\n",
    "\n",
    "# PRODUCT GEOMETRY\n",
    "\n",
    "screenshots = product.torus_embedding.show(device)\n",
    "\n",
    "# K-STEREOGRAPHIC MODEL\n",
    "\n",
    "#stereographic.distance.show(x,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave(f'training.gif', screenshots, duration=1/24)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming bht_points is already defined\n",
    "x_vals = [coord[0] for coord in bht_points.values()]\n",
    "y_vals = [coord[1] for coord in bht_points.values()]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_vals, y_vals, c=COLORS.grey, s=10)\n",
    "\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")  # for square geometry\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.grid(True)\n",
    "plt.title(\"BHT Points\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff54ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "\n",
    "platforms = cl.get_platforms()\n",
    "for platform in platforms:\n",
    "  print(f\"Platform: {platform.name}\")\n",
    "  for device in platform.get_devices():\n",
    "    print(f\"  Device: {device.name}\")\n",
    "    print(f\"    Type: {cl.device_type.to_string(device.type)}\")\n",
    "    print(f\"    Max compute units: {device.max_compute_units}\")\n",
    "    print(f\"    Global memory: {device.global_mem_size / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"    Max clock freq: {device.max_clock_frequency} MHz\")\n",
    "    print(f\"    Max allocable memory: {device.max_mem_alloc_size / (1024 ** 3):.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn.test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
